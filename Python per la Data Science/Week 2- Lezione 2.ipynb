{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hQ7xoDpT3PV"
   },
   "source": [
    "# Dalle ANN alle reti deep\n",
    "\n",
    "Prima di passare alle Deep Neural Networks (DNN) è importante analizzare bene alcuni aspetti delle ANN che ne hanno limitato la diffusione e l'uso fino al recente avvento del deep learnig.\n",
    "\n",
    "Tra le varie cose, le reti deep prendono il loro nome proprio dal fatto che sono molto profonde, ossia composte da una sequenza di numerosi livelli. Dunque, uno degli aspetti cruciali da investigare è l'effetto che la profondità della rete ha sulle performance di un MLP. A tal fine, partiamo proprio dall'esempio dell'esercizio della lezione precedente e mostriamo come varia la curva dell'accuracy al variare del numero livelli, ma tenendo costante il numero complessivo di neuroni.\n",
    "\n",
    "L'esecuzione della fase di addestramento del codice seguente potrebbe richiedere **una quantità di tempo considerevole**. Per questo motivo, è presente una cella alternativa in grado di caricare i parametri e le variabili risultanti da un'esecuzione della cella precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOceUF9CqYK9"
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#                                                                                   #\n",
    "#   ATTENZIONE: eseguire questa cella SOLO SE SI VUOLE EFFETTUARE L'ADDESTRAMENTO.  #\n",
    "#               Eseguire la cella seguente se si vogliono caricare le variabili     #\n",
    "#               necessarie già pronte per l'uso. L'esecuzione di questa cella può   #\n",
    "#               richiedere diversi minuti!                                          #\n",
    "#                                                                                   #\n",
    "##################################################################################### \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Caricamento dei dati\n",
    "digits = load_digits()\n",
    "\n",
    "#Preparazione del dataset\n",
    "dati = digits.data           \n",
    "classi = digits.target\n",
    "\n",
    "dataTrain, dataTest, classiTrain, classiTest = train_test_split(dati, classi, test_size = 0.20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataTrain)\n",
    "\n",
    "dataTrainScalato = scaler.transform(dataTrain)\n",
    "dataTestScalato = scaler.transform(dataTest)\n",
    "\n",
    "#Range dei valori per le epoche\n",
    "epochRange = np.arange(1, 500, 5)\n",
    "\n",
    "#Addestramento per due MLP, uno con 3 livelli hidden e uno con 9\n",
    "trainScores_MLP3, validationScores_MLP3 = validation_curve(MLPClassifier(hidden_layer_sizes=(10,50,10), solver='sgd', activation='tanh'), \n",
    "                                             dataTrainScalato, \n",
    "                                             classiTrain, \n",
    "                                             param_name=\"max_iter\", \n",
    "                                             param_range=epochRange,\n",
    "                                             cv=3, \n",
    "                                             scoring=\"accuracy\", \n",
    "                                             n_jobs=-1)\n",
    "\n",
    "trainScores_MLP9, validationScores_MLP9 = validation_curve(MLPClassifier(hidden_layer_sizes=(10,10,10,10,10,5,5,5,5), solver='sgd', activation='tanh'), \n",
    "                                             dataTrainScalato, \n",
    "                                             classiTrain, \n",
    "                                             param_name=\"max_iter\", \n",
    "                                             param_range=epochRange,\n",
    "                                             cv=3, \n",
    "                                             scoring=\"accuracy\", \n",
    "                                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1611872379414,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "om_tK2Cc_nbi",
    "outputId": "37940bb2-d5b8-4373-d1d1-a647e99cbf88"
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#                                                                                   #\n",
    "#   ATTENZIONE: eseguire questa cella SOLO SE SI VOGLIONO CARICARE I DATI PRONTI.   #\n",
    "#               Non è necessario eseguire questa cella se si è eseguita quella      #\n",
    "#               precedente, dove è stato effettuato l'addestramento.                #\n",
    "#                                                                                   #\n",
    "##################################################################################### \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open('preElaborati1.pkl', 'rb') as f:\n",
    "    trainScores_MLP3, validationScores_MLP3, trainScores_MLP9, validationScores_MLP9, epochRange = pickle.load(f)\n",
    "\n",
    "print('Dati pre-elaborati caricati con successo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1611872382276,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "ZXTy-57d_fPB",
    "outputId": "db12b5c5-6769-4b70-a366-74faf29548b8"
   },
   "outputs": [],
   "source": [
    "#Visualizzazione\n",
    "trainMean_MLP3 = np.mean(trainScores_MLP3, axis=1)\n",
    "trainStd_MLP3 = np.std(trainScores_MLP3, axis=1)\n",
    "valMean_MLP3 = np.mean(validationScores_MLP3, axis=1)\n",
    "valStd_MLP3 = np.std(validationScores_MLP3, axis=1)\n",
    "\n",
    "trainMean_MLP9 = np.mean(trainScores_MLP9, axis=1)\n",
    "trainStd_MLP9 = np.std(trainScores_MLP9, axis=1)\n",
    "valMean_MLP9 = np.mean(validationScores_MLP9, axis=1)\n",
    "valStd_MLP9 = np.std(validationScores_MLP9, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.plot(epochRange, trainMean_MLP3, label=\"Training Accuracy\", color=\"black\")\n",
    "plt.plot(epochRange, valMean_MLP3, label=\"Cross-validation Accuracy\", color=\"dimgrey\")\n",
    "plt.fill_between(epochRange, trainMean_MLP3 - trainStd_MLP3, trainMean_MLP3 + trainStd_MLP3, color=\"gray\")\n",
    "plt.fill_between(epochRange, valMean_MLP3 - valStd_MLP3, valMean_MLP3 + valStd_MLP3, color=\"gainsboro\")\n",
    "plt.title(\"Tre livelli\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.plot(epochRange, trainMean_MLP9, label=\"Training Accuracy\", color=\"black\")\n",
    "plt.plot(epochRange, valMean_MLP9, label=\"Cross-validation Accuracy\", color=\"dimgrey\")\n",
    "plt.fill_between(epochRange, trainMean_MLP9 - trainStd_MLP9, trainMean_MLP9 + trainStd_MLP9, color=\"gray\")\n",
    "plt.fill_between(epochRange, valMean_MLP9 - valStd_MLP9, valMean_MLP9 + valStd_MLP9, color=\"gainsboro\")\n",
    "plt.title(\"Nove livelli\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcgKbwYfodO0"
   },
   "source": [
    "Come si vede dai grafici delle curve di addestramento, sebbene in entrambi i casi il numero totale di neuroni nei livelli hidden sia sempre 70, la presenza di un maggior numero di livelli ha un grosso impatto sulla capacità di apprendimento della rete. Sebbene possa risultare inatteso, questo comportamento è (principalmente) legato alla propagazione dei gradienti durante la fase di addestramento. Difatti, la presenza di un numero maggiore di livelli può causare due fenomeni noti come Vanishing Gradient e Exploding Gradient: \n",
    "\n",
    "*   nel primo caso, il valore dei gradienti (usato per aggiornare i pesi dei neuroni) inizia a diventare cosi piccolo da risultare sostanzialmente insufficiente a generare una variazione efficace dei pesi (e quindi la rete non apprende)\n",
    "*   nel secondo caso, il gradiente si accumula, causando grosse variazioni dei pesi e dunque grosse oscillazioni nei pesi (con conseguente oscillazione delle metriche di performance)\n",
    "\n",
    "Tale problema ha limitato lo sviluppo in profondità delle ANN che, di conseguenza, hanno invece visto lo sviluppo di architetture con pochi, ma ampi, livelli.\n",
    "\n",
    "Sebbene questo problema sussista tutt'ora (e diversi esperti credano possa essere solo limitato e mai completamente risolto), tre fattori hanno contribuito alla nascita delle deep neural networks, infrangendo il limite dei pochi livelli hidden:\n",
    "\n",
    "1.   Lo sviluppo di nuove soluzioni hardware (più performanti e capaci di lavorare con rappresentazioni su più bit)\n",
    "2.   La disponibilità di elevate moli di dati (necessari al crescere del numero complessivo di neuroni da addestrare)\n",
    "3.   Il design di nuove funzioni di attivazione e algoritmi di ottimizzazione, progettati per risentire meno del problema\n",
    "\n",
    "Scikit-learn supporta tutte queste caratteristiche, dato che è in grado di sfruttare hardware recenti (come ad esempio l'accellerazione hardware basata su GPU), e permette di utilizzare diversi ottimizzatori e funzioni di attivazione. \n",
    "\n",
    "Ciononostante, scikit-learn non è lo strumento più adatto per il design e l'addestramento di Deep Neural Networks. Infatti, scikit-learn è progettato per supportare in maniera uniforme e coerente una vasta gamma di algoritmi e tecniche di machine learning, le cui caratteristiche e necessità sono tuttavia differenti da quelle proprie del mondo delle deep neural network. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cc-22qPupxq"
   },
   "outputs": [],
   "source": [
    "#TASK: che succede se si ripete l'esecuzione utilizzando un altro ottimizzatore e/o un'altra funzione di attivazione?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD99CkXF3vHS"
   },
   "source": [
    "# ANN con PyTorch\n",
    "\n",
    "PyTorch (anche in questo caso \"Py\" si pronuncia come $\\pi$ in inglese) è un framework open source nato per il design e l'addestramento di deep neural networks. Basato su Torch, ha due caratteristiche che lo rendono particolarmente efficace per il Deep Learning: \n",
    "\n",
    "*   L'introduzione di tensori (molto simili agli NDarray) nativamente in grado di essere manipolati da GPU\n",
    "*   Differenziazione automatica (ossia la capacità di determinare la derivata di funzioni a piacere ottenute come composizione di funzioni base messe a disposizione dal framework)\n",
    "\n",
    "Per capire i vantaggi di questi punti, riprendiamo lo stesso problema della classificazione delle cifre e progettiamolo nuovamente usando PyTorch.\n",
    "\n",
    "Partiamo dagli import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4457,
     "status": "ok",
     "timestamp": 1611872389214,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "fAIGX_z4z_BD",
    "outputId": "77564442-96ba-417a-a09b-b6d74c291d4c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYm-1Y7d1pxj"
   },
   "source": [
    "Escludendo NumPy e Matplotlib, ci sono diverse a cui prestare attenzione\n",
    "\n",
    "*   `torch` è namespace di PyTorch\n",
    "*   `torchvision` è il package che contiene numerosi modelli, dataset e algoritmi per la computer vision. Nel nostro caso importiamo due moduli: `dataset`, che contiene una serie di dataset pronti per l'uso; `transforms`, che fornisce alcune primitive per la manipolazione dei dati\n",
    "*   `torch.nn` è il modulo di alto livello (basato sulle sottostanti funzionalità di derivazione automatica) progettato per definire complesse (o meno) funzioni di attivazione e di loss per reti neurali, le cui derivate saranno automaticamente calcolate\n",
    "*   `torch.optim` è il modulo che include differenti algoritmi di ottimizzazione \n",
    "*   `torch.Tensor` introduce il concetto di tensore, ossia un oggetto estremamente simile agli NDarray di NumPy, ma sul quale possono nativamente operare alcune GPU NVidia\n",
    "*   `torch.utils.data.DataLoader` è il modulo che permette di caricare, in maniera rapida ed efficiente, i dati utilizzati poi dalla rete \n",
    "\n",
    "Si noti che l'import del modulo `Tensor` non è strettamente necessario, ed è stato qui riportato principalmente per questioni didattiche.\n",
    "\n",
    "Come sempre, dettagli e funzionalità supportate possono variare tra le varie versioni. In questo corso fare riferimento alla versione `1.5.0` per PyTorch e `0.6.0` per Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FEqBR3m_6h6"
   },
   "source": [
    "## Caricamento e preparazione dei dati\n",
    "\n",
    "Come per scikit-learn, è possibile utilizzare alcune funzionalità di PyTorch per accedere ad alcuni dataset famosi. Mnist è tra questi. Per scaricarlo, usiamo il modulo `torchvision.datasets`.\n",
    "\n",
    "Come fatto nel caso di scikit-learn, anche in questo caso useremo la versione linearizzata dell'immagine come vettore di feature per la nostra ANN. In questo caso usiamo le funzionalità messe a disposizione da `torchvision.transforms`, ricordandoci che in PyTorch tutto è un tensore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "0b885c5e6d0f46f7baae7269a99a2452",
      "276477d790254288b6cfd89375df4089",
      "ee5fa6da69be4bfebac1cf3e8f4679c7",
      "01e96c9009f6408b92f2915719b1475f",
      "e3d36433bbf14ed39d3d42edffef1d09",
      "f8f9e19502d54dd595a8bbfe9aae728f",
      "4fb0be940d8444198708855db05c3505",
      "4475099547014107860f85401acf7c0a",
      "1efd6cdaeee040a48d1b16b8f3985b1a",
      "e2bb0f1f3db1490caa608c3f9abfc523",
      "04f5b74287bf4be0b4e0d044e60e7aa3",
      "19acc9e6cb0146d89967f577562943e4",
      "bbcbedb4b3d84eccb71277ea962371f7",
      "227a416ebfb54db5bb7f1303c5519492",
      "c6d8da9fbad04865aa0c5fc537bf8e36",
      "feeef76f15c14b25b72461212963aa7d",
      "0a50ca62a50e46199e300cef4a324412",
      "8aa68a2c68e84219a16b956ae7bdebe1",
      "2740c04269d04b938ba71d0c5abec755",
      "0f1975c61ee049a7b80a82768357bb6a",
      "9f49e92ee7d64ddba0f95d03161ae4a2",
      "6ed78314be564c7082a0280f1fd4033f",
      "d3ef88cfb40a4640bc25df287b56c583",
      "891e7615ddfe423984e003f35040f441",
      "d98b22b170e6481288a03facddedf448",
      "afe68f44df754036bb85591d97732a46",
      "b6d970d4a7eb4144a857b37baa070adc",
      "cf3e3ef5e9b04210901c79b93089f99b",
      "bf8ee539368d450dbb60cccb42c99fb5",
      "68cae1c4adcd43f196900dad5555f7c0",
      "23d5de05d2af40088f1de2c58427b707",
      "dd0797b88e694c0e878af40d24eb0de5"
     ]
    },
    "executionInfo": {
     "elapsed": 6657,
     "status": "ok",
     "timestamp": 1611872394444,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "I7_ltqsI-gbQ",
    "outputId": "a9cee312-1a27-4f44-c132-72bef0cad887"
   },
   "outputs": [],
   "source": [
    "#Definizione della funzione di linearizzazione e normalizzazione dell'input\n",
    "trasf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainingSet = datasets.MNIST('MNIST_data/', download=True, train=True, transform=trasf)\n",
    "testSet = datasets.MNIST('MNIST_data/', download=True, train=False, transform=trasf)\n",
    "\n",
    "trainingLoader = DataLoader(trainingSet, batch_size = 64, shuffle = True)\n",
    "testLoader = DataLoader(testSet, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPKdHRhnF0p8"
   },
   "source": [
    "Queste poche righe di codice ci danno già la possibilità di approfondire diversi aspetti\n",
    "\n",
    "Come fatto nel caso di scikit-learn, non solo dobbiamo linearizzare l'immagine, ma dobbiamo anche normalizzare i valori dei pixel. Data la necessità di effettuare due trasformazioni, usiamo il metodo `transforms.Compose` per definire un array di trasformazioni da applicare ai dati di input\n",
    "\n",
    "1.   `ToTensor()` permette di trasformare i dati da `ndarry` a `torch.Tensor`;\n",
    "2.   il metodo `Normalize` accetta un valore di media e uno di varianza per ognuno dei canali (es. RGB per le immagini naturali) per poi eseguire l'operazione di normalizzazione. MNIST contiene immagini in bianco e nero, su un singolo canale (dunque è sufficiente avere un singolo valore di media ed un singolo valore di varianza). Si noti che in linea teorica, cosi come fatto per scikit-learn, avremmo dovuto calcolare la media e la varianza sul training set e poi applicare la trasformazione al training e al test set. Nel caso di MNIST, tuttavia, data la particolare tipologia di immagini, usare il valore 0.5 per entrambi permette di ottenere (con buona approssimazione) la trasformazione desiderata, senza dover \"sprecare\" potenza computazionale per il calcolo dei valori precisi.\n",
    "\n",
    "Un altro metodo interessante è `datasets.MNIST`. In questo caso il metodo scaricherà le immagini nella cartella desiderata, prelevandole dal training set o dal test set in base al valore del parametro booleano `train`. Si noti anche che il metodo accetta in ingresso la funzione di trasformazione precedentemente definita e discussa. La motivazione sta nel fatto che il dataset cosi definito è poco più di un funzionale il cui compito è memorizzare tutte le informazioni che saranno poi utilizzate dal modulo di caricamento vero e proprio. \n",
    "\n",
    "Nel caso specifico, chi si occupa del caricamento dei dati è il `DataLoader`. Si tratta di un modulo che permette di disaccoppiare il caricamento dei dati dalla loro elaborazione. Questo passaggio si rende molto utile in quanto l'addestramento delle reti deep tende (praticamente sempre) ad essere più efficace se eseguito per batch di dati. In sostanza, invece di aggiornare i pesi dei neuroni per ogni campione analizzato (strategia nota come \"training by pattern\") o dopo aver elaborato tutti i campioni del training set (strategia nota come \"training by epoch\"), si aggiornano i pesi ad ogni batch, ossia dopo aver elaborato una porzione dei dati di training (noto come \"batch training\"). La dimensione del batch è impostabile tramite il parametro batch_size (64 nell'esempio). In questo contesto l'uso di un `DataLoader` si rivela estremamente utile in quanto sarà quest'ultimo ad occuparsi di generare una opportuna suddivisione in batch, passandoli di volta in volta all'algoritmo di addestramento vero e proprio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LR7ZMNAWyN2"
   },
   "source": [
    "## Definizione della rete e addestramento\n",
    "\n",
    "A differenza di quanto visto con scikit-learn, in PyTorch è compito del programmatore definire i dettagli dell'architettura e del processo di addestramento. Sebbene all'inizio questo possa risultare complesso, con il tempo la libertà espressiva permessa da questo approccio ripagano ampiamente lo sforzo iniziale. PyTorch fornisce diverse primitive per supportare tale processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtAEuGg4lF5i"
   },
   "source": [
    "## Design della rete\n",
    "\n",
    "Il primo passo è la definizione dell'architettura della nostra rete neurale artificiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1611872454837,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "iHVvt-OAYTfP",
    "outputId": "aa0c9999-61ed-4230-df91-52f460a337ac"
   },
   "outputs": [],
   "source": [
    "#Caratteristiche dei liveli\n",
    "dimensioneInput = 784         #Dato che in questo caso le immagini in ingresso sono 28x28x1 pixel\n",
    "livelliHidden = [128, 64]     #Numero di neuroni per ogni livello hidden\n",
    "dimensioneOutput = 10         #Numero di neuroni nel livello di output (pari al numero di classi)\n",
    "\n",
    "#Definizione della rete\n",
    "modello = nn.Sequential(nn.Linear(dimensioneInput, livelliHidden[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(livelliHidden[0], livelliHidden[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(livelliHidden[1], dimensioneOutput),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "#Visualizzazione\n",
    "print(modello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA8gwUoVZOOk"
   },
   "source": [
    "Il metodo `nn.Sequential` permette la definizione di una ANN di tipo feedforward, costuita collegando in sequenza i livelli neurali che sono passati come input. Nel caso specifico costruiamo una rete con tre livelli di tipo `nn.Linear`, definendo per ognuno di essi il numero di ingressi attesi e uscite da generare. Per i primi due livelli, la funzione di attivazione usata è una *ReLu* (computazionalmente più efficiente). Per l'ultimo livello si usa invece una *LogSoftmax* (particolarmente adatta a gestire la classificazione multi classe, oltre ad essere caratterizzata da una elevata stabilità numerica e una forte penalizzazione per gli errori commessi durante l'addestramento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_nU_5dtlwW_"
   },
   "source": [
    "## Scelta del device di addestramento\n",
    "\n",
    "Definita l'architettura del modello, si può caricare il modello stesso sulla GPU (se disponibile) per velocizzare i tempi di addestramento. PyTorch permette di verificare velocemente se il sistema utilizzato presenta una GPU compatibile. In caso contrario, PyTorch userà la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11082,
     "status": "ok",
     "timestamp": 1611872466926,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "DZViwUk1kpsE",
    "outputId": "035268f0-bfbb-4ba8-fb26-535431d751c3"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "modello.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov7TUjMrm6LY"
   },
   "source": [
    "## Definizione dell'algoritmo di addestramento\n",
    "\n",
    "Prima di procedere con la definizione dell'algoritmo di apprendimento è necessario definire la *funzione di errore* (in inglese nota come loss function) che sarà minimizzata dall'algoritmo durante il processo di apprendimento. In questo esempio useremo la \"Negative Log-Likelihood\" (implementata dal modulo `nn.NLLLoss()`) in quanto ben si presta ad una classificazione multi-classe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9382,
     "status": "ok",
     "timestamp": 1611872466927,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "pUVTaReknnqG"
   },
   "outputs": [],
   "source": [
    "lossFun = nn.NLLLoss()     \n",
    "optimizer = optim.SGD(modello.parameters(), lr = 0.003, momentum = 0.9)     #lr = Learning rate            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPt6blGGVkh"
   },
   "source": [
    "Dopo aver definito la funzione di loss e l'algoritmo di ottimizzazione che si desidera utilizzare, possiamo realizzare l'algoritmo di addestramento vero e proprio. Si tratta sostanzialmente di realizzare un ciclo che iteri l'addestramento per ognuno dei batch generati dal Dataloader. Questo processo, deve poi essere ripetuto tante volte quante vogliamo che siano il numero di epoche di addestramento. \n",
    "\n",
    "L'esecuzione della fase di addestramento del codice seguente potrebbe richiedere **una quantità di tempo considerevole**. Per questo motivo, è presente una cella alternativa in grado di caricare i parametri e le variabili risultanti da un'esecuzione della cella precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155969,
     "status": "ok",
     "timestamp": 1611867184839,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "u3e7F6cQrIo2",
    "outputId": "95ed38f8-aca0-4bd5-a25b-61825ce8aa07"
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#                                                                                   #\n",
    "#   ATTENZIONE: eseguire questa cella SOLO SE SI VUOLE EFFETTUARE L'ADDESTRAMENTO.  #\n",
    "#               Eseguire la cella seguente se si vogliono caricare le variabili     #\n",
    "#               necessarie già pronte per l'uso. L'esecuzione di questa cella può   #\n",
    "#               richiedere diversi minuti!                                          #\n",
    "#                                                                                   #\n",
    "##################################################################################### \n",
    "\n",
    "epoche = 15\n",
    "lossTraining = []\n",
    "\n",
    "#Ciclo di addestramento sulle epoche\n",
    "for e in range(epoche):\n",
    "    #Variabile di appoggio per la loss dell'epoca corrente\n",
    "    lossEpoca = 0\n",
    "\n",
    "    #Ciclo sui batch, per l'e-esima epoca\n",
    "    for datiBatch, labelsBatch in trainingLoader:\n",
    "\n",
    "        #Linearizzazione delle immagini nel batch corrente\n",
    "        datiBatch = datiBatch.view(datiBatch.shape[0], -1)\n",
    "\n",
    "        #Gestione dell'eventuale GPU\n",
    "        if torch.cuda.is_available():\n",
    "          datiBatch = datiBatch.cuda()\n",
    "          labelsBatch = labelsBatch.cuda()\n",
    "            \n",
    "        #Passo di forward\n",
    "        output = modello(datiBatch) \n",
    "        loss = lossFun(output, labelsBatch) \n",
    "\n",
    "        #Azzeramento dei gradienti\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        #Passo di back-propagation dell'errore\n",
    "        loss.backward()\n",
    "        \n",
    "        #Aggiornamento dei pesi del modello\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Aggiornamento della loss per l'epoca corrente, sommando la loss del batch attuale\n",
    "        lossEpoca += loss.item()*datiBatch.size(0)    \n",
    "\n",
    "    #Aggiornamento dell'array delle loss (per ogni epoca)\n",
    "    lossTraining.append(lossEpoca/len(trainingLoader))\n",
    "    \n",
    "    #Stampa delle informazioni correnti\n",
    "    print(\"Epoca {} - Loss sul TrainingSet: {}\".format(e, lossTraining[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1846,
     "status": "ok",
     "timestamp": 1611872466927,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "k6qLmC-gx5Y7",
    "outputId": "01ae246a-a235-4af5-fab9-3771cbadb2f3"
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#                                                                                   #\n",
    "#   ATTENZIONE: eseguire questa cella SOLO SE SI VOGLIONO CARICARE I DATI PRONTI.   #\n",
    "#               Non è necessario eseguire questa cella se si è eseguita quella      #\n",
    "#               precedente, dove è stato effettuato l'addestramento. Nota che il    #\n",
    "#               salvataggio e caricamento sono qui riportati solo per questioni     #\n",
    "#               legate al tempo di esecuzione dell'algoritmo. Nelle prossime        #\n",
    "#               lezioni sarà spiegata in dettaglio la procedura di salvataggio e    #\n",
    "#               caricamento di ANN/CNN con PyTorch.                                 #\n",
    "#                                                                                   #\n",
    "##################################################################################### \n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('preElaborati2.pkl', 'rb') as f:\n",
    "    epoche, lossTraining = pickle.load(f)\n",
    "modello.load_state_dict(torch.load('preElaborato.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "print('Dati pre-elaborati caricati con successo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4XGrnZ3rI7S"
   },
   "source": [
    "Quello che abbiamo fatto è richiedere, per ogni epoca un batch (dati e labels) al Dataloader definito precedentemente. In particolare, per i dati, abbiamo inoltre effettuato la linerizzazione (dato che consideriamo i valori dei pixel come features). Nota che anche in questo caso abbiamo dovuto controllare se fosse disponibile una GPU compatibile. In quest'ultimo caso è necessario infatti comunicare esplicitamente al sistema che il modello (e quindi eventuali dati di cui ha bisogno e/o che genera) vanno gestiti tramitte GPU.\n",
    "\n",
    "Si noti che prima di ogni passo di backward, resettiamo i gradienti. Questo passaggio è necessario in quanto PyTorch accumula i gradienti per esecuzioni successive di back-propagation. Questa funzionalità, molto utile nel caso dell'addestramento di reti ricorrenti (che non vedremo in questo corso), è invece deleterio nel caso dell'addestramento di reti di tipo feed-forward.\n",
    "\n",
    "Due variabili meritano un ulteriore appprofondimento: `lossEpoca` e `lossTraining`. Per la prima nota che moltiplichiamo il valore di loss calcolato per il numero di elementi nel batch corrente. Questo passaggio è necessario in quanto quella che si ottiene dall'applicazione di `criterion` è la loss media del batch attuale (dunque moltiplicandola per il totale degli elementi in quel batch, otteniamo la loss complessiva del batch). Viceversa, dato che `lossEpoca` a valle del passo precedente ha accumulato le loss complessive per tutti gli elementi di tutti i batch (ossia tutto il training set), volendo visualizzare la loss media dell'intera epoca, dobbiamo dividere tale valore per il numero di batch in cui il training set è stato diviso.\n",
    "\n",
    "A questo punto, possiamo visualizzare graficamente l'andamento della loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1611872470332,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "kIGKv9jw6fA1",
    "outputId": "e6a8ae37-7eba-4d22-a6ca-9723e509d6ac"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, epoche, 1), lossTraining, label=\"Training Loss\", color=\"black\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MejpKsTv7XWJ"
   },
   "source": [
    "Si noti che la prima epoca è etichettata come 0 solo per questioni di coerenza con l'indexing di Python. Tuttavia, il primo valore di loss si è in realtà ottenuto alla fine della prima epoca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XQlk30PsJ9H"
   },
   "source": [
    "## Valutazione delle performance\n",
    "\n",
    "L'ultimo passaggio che resta da compiere è la valutazione delle performance sul test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5572,
     "status": "ok",
     "timestamp": 1611872477899,
     "user": {
      "displayName": "Stefano Marrone",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj7UYQUq4o1dqiJKQAfAybDDzcHqi0EhyshODI0Bg=s64",
      "userId": "07649195604695653363"
     },
     "user_tz": -60
    },
    "id": "soJpmpZ6sN28",
    "outputId": "ec8ccd56-a0c9-448b-a796-9cd7b7411916"
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#                                                                                   #\n",
    "#   L'esecuzione di questa cella può richiedere diversi minuti.                     #\n",
    "#                                                                                   #\n",
    "#####################################################################################\n",
    "\n",
    "campioniCorretti, campioniTotali = 0, 0                      #Valori di accumulo delle immagini analizzate\n",
    "for datiTest, lablesTest in testLoader:\n",
    "  for i in range(len(lablesTest)):\n",
    "    campione = datiTest[i].view(1, 784)\n",
    "\n",
    "    #Gestione GPU\n",
    "    if torch.cuda.is_available():\n",
    "      campione = campione.cuda()\n",
    "    \n",
    "    #Stiamo in inferenza, quindi non serve calcolare i gradienti\n",
    "    with torch.no_grad():\n",
    "      output = modello(campione)\n",
    "\n",
    "    #Calcolo della classe predetta\n",
    "    probs = torch.exp(output)\n",
    "    probsList = list(probs.cpu().numpy()[0])\n",
    "    classePred = probsList.index(max(probsList))\n",
    "\n",
    "    #Valutazione della correttezza della predizione\n",
    "    classeVera = lablesTest.numpy()[i]\n",
    "    if(classeVera == classePred):\n",
    "      campioniCorretti += 1\n",
    "    campioniTotali += 1\n",
    "\n",
    "print(\"Numero di campioni nel test set =\", campioniTotali)\n",
    "print(\"\\nAccuracy sul test set =\", (campioniCorretti/campioniTotali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu9SB6gb9nqz"
   },
   "source": [
    "Si noti che per ottenere le probabilità predette abbiamo valutato l'esponenziale dell'output (dato che avevamo scelto di usare la LogSoftmax). Tuttavia questo passaggio è meramente didattico, in quanto il logaritmo preserva l'ordinamento dei valori (e quindi tutti i passaggi successivi avrebbero comunque funzionato correttamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWg_JNmtxoAO"
   },
   "source": [
    "# Esercizio\n",
    "\n",
    "Ripetere l'esercizio sull'addestramento della ANN per la classificazione del dataset MNIST, includendo \n",
    "\n",
    "*   Divisione del training set in training e validation\n",
    "*   Aggiunta della visualizzazione dell'accuracy e della loss per il training set e per validation set alla fine di ogni epoca\n",
    "*   Visualizzazione delle training curve\n",
    "*   Calcolo dell'errore sul test set\n",
    "\n",
    "Per lo split del dataset è possibile usare la seguente funzione\n",
    "\n",
    "```\n",
    "def train_val_dataset(dataset, validation=0.20):\n",
    "    trainIdx, valIdx = train_test_split(list(range(len(dataset))), test_size=validation)\n",
    "    trainingSet = Subset(dataset, trainIdx)\n",
    "    validationSet = Subset(dataset, valIdx)\n",
    "    return(trainingSet, validationSet)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHTHP9cNyEWZ"
   },
   "source": [
    "# Soluzione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6am47jpWEjE_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Funzione per lo split del training set\n",
    "def train_val_dataset(dataset, validation=0.20):\n",
    "    trainIdx, valIdx = train_test_split(list(range(len(dataset))), test_size=validation)\n",
    "    trainingSet = Subset(dataset, trainIdx)\n",
    "    validationSet = Subset(dataset, valIdx)\n",
    "    return(trainingSet, validationSet)\n",
    "\n",
    "#Creiamo un metodo che, a partire da Dati e Labels, calcoli Loss e Accuracy (dato che lo useremo per training, test e validation)\n",
    "def valutaOutputEPerformance(modello, criterion, dati, labels):\n",
    "  if torch.cuda.is_available():\n",
    "    dati = dati.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "  output = modello(dati) \n",
    "  loss = criterion(output, labels) \n",
    "\n",
    "  campioniCorretti, campioniTotali = 0, 0  \n",
    "  for i in range(len(labels)):\n",
    "    campione = dati[i].view(1, 784)\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "      outputCampione = modello(campione)\n",
    "\n",
    "    #Calcolo della classe predetta\n",
    "    probs = torch.exp(outputCampione)\n",
    "    probsList = list(probs.cpu().numpy()[0])\n",
    "    classePred = probsList.index(max(probsList))\n",
    "\n",
    "    #Valutazione della correttezza della predizione\n",
    "    classeVera = labels.cpu().numpy()[i]\n",
    "    if(classeVera == classePred):\n",
    "      campioniCorretti += 1\n",
    "    campioniTotali += 1\n",
    "\n",
    "  accuracy = campioniCorretti/campioniTotali\n",
    "  return(output, loss, accuracy)\n",
    "\n",
    "trasf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainingSet = datasets.MNIST('MNIST_data/', download=True, train=True, transform=trasf)\n",
    "trainingSet, validationSet = train_val_dataset(trainingSet, validation=0.20)\n",
    "testSet = datasets.MNIST('MNIST_data/', download=True, train=False, transform=trasf)\n",
    "trainingLoader = DataLoader(trainingSet, batch_size=64, shuffle=True)\n",
    "validationLoader = DataLoader(validationSet, batch_size=64, shuffle=True)\n",
    "testLoader = DataLoader(testSet, batch_size=64, shuffle=True)\n",
    "\n",
    "dimensioneInput = 784         \n",
    "livelliHidden = [128, 64]     \n",
    "dimensioneOutput = 10         \n",
    "\n",
    "modello = nn.Sequential(nn.Linear(dimensioneInput, livelliHidden[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(livelliHidden[0], livelliHidden[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(livelliHidden[1], dimensioneOutput),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "modello.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()                      \n",
    "optimizer = optim.SGD(modello.parameters(), lr=0.003, momentum=0.9)\n",
    "epoche = 15 \n",
    "lossTraining = []\n",
    "accuracyTraining = []\n",
    "lossValidation = []\n",
    "accuracyValidation = []\n",
    "\n",
    "for e in range(epoche):\n",
    "  lossTrainEpoca = 0\n",
    "  lossValEpoca = 0\n",
    "  for datiBatchTrain, labelsBatchTrain in trainingLoader:\n",
    "      datiBatchTrain = datiBatchTrain.view(datiBatchTrain.shape[0], -1)   \n",
    "      outputTrain, lossTrain, accuracyTrain = valutaOutputEPerformance(modello, criterion, datiBatchTrain, labelsBatchTrain)      \n",
    "      optimizer.zero_grad()\n",
    "      lossTrain.backward()\n",
    "      optimizer.step()\n",
    "      lossTrainEpoca += lossTrain.item()*datiBatchTrain.size(0)    \n",
    "  lossTraining.append(lossTrainEpoca/len(trainingLoader))\n",
    "  accuracyTraining.append(accuracyTrain)\n",
    "\n",
    "  #Calcolo delle performance sul validation set, ad ogni fine epoca\n",
    "  for datiBatchVal, labelsBatchVal in validationLoader:\n",
    "      datiBatchVal = datiBatchVal.view(datiBatchVal.shape[0], -1)   \n",
    "      outputVal, lossVal, accuracyVal = valutaOutputEPerformance(modello, criterion, datiBatchVal, labelsBatchVal)      \n",
    "      lossValEpoca += lossVal.item()*datiBatchVal.size(0)    \n",
    "  lossValidation.append(lossValEpoca/len(validationLoader))\n",
    "  accuracyValidation.append(accuracyVal)\n",
    "  \n",
    "  print(\"Epoca {}:\".format(e))\n",
    "  print(\"Loss sul Training Set: {} - Accuracy sul Training Set: {}\".format(lossTraining[-1:], np.mean(accuracyTraining)))\n",
    "  print(\"Loss sul Validation Set: {} - Accuracy sul Validation Set: {}\".format(lossValidation[-1:], np.mean(accuracyValidation)))\n",
    "  print(\"--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "#Visualizzazione delle training curves\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.plot(np.arange(0, epoche, 1), lossTraining, label=\"Training Loss\", color=\"black\")\n",
    "plt.plot(np.arange(0, epoche, 1), lossValidation, label=\"Validation Loss\", color=\"dimgrey\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.plot(np.arange(0, epoche, 1), accuracyTraining, label=\"Training Accuracy\", color=\"black\")\n",
    "plt.plot(np.arange(0, epoche, 1), accuracyValidation, label=\"Validation Accuracy\", color=\"dimgrey\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "#Calcolo delle performance finali sul test set\n",
    "accuracyTest = []\n",
    "campioniTotaliTest = 0\n",
    "for datiBatchTest, labelsBatchTest in testLoader:\n",
    "  datiBatchTest = datiBatchTest.view(datiBatchTest.shape[0], -1)   \n",
    "  outputTest, lossTest, accuracyT = valutaOutputEPerformance(modello, criterion, datiBatchTest, labelsBatchTest)       \n",
    "  accuracyTest.append(accuracyT)\n",
    "  campioniTotaliTest += datiBatchTest.size(0);\n",
    "print(\"Numero di campioni nel test set =\", campioniTotaliTest)\n",
    "print(\"\\nAccuracy sul test set =\", np.mean(accuracyTest))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 2- Lezione 2_Coursera_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e96c9009f6408b92f2915719b1475f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4475099547014107860f85401acf7c0a",
      "placeholder": "​",
      "style": "IPY_MODEL_4fb0be940d8444198708855db05c3505",
      "value": " 9920512/? [00:20&lt;00:00, 3282482.17it/s]"
     }
    },
    "04f5b74287bf4be0b4e0d044e60e7aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_227a416ebfb54db5bb7f1303c5519492",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bbcbedb4b3d84eccb71277ea962371f7",
      "value": 0
     }
    },
    "0a50ca62a50e46199e300cef4a324412": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2740c04269d04b938ba71d0c5abec755",
       "IPY_MODEL_0f1975c61ee049a7b80a82768357bb6a"
      ],
      "layout": "IPY_MODEL_8aa68a2c68e84219a16b956ae7bdebe1"
     }
    },
    "0b885c5e6d0f46f7baae7269a99a2452": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee5fa6da69be4bfebac1cf3e8f4679c7",
       "IPY_MODEL_01e96c9009f6408b92f2915719b1475f"
      ],
      "layout": "IPY_MODEL_276477d790254288b6cfd89375df4089"
     }
    },
    "0f1975c61ee049a7b80a82768357bb6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_891e7615ddfe423984e003f35040f441",
      "placeholder": "​",
      "style": "IPY_MODEL_d3ef88cfb40a4640bc25df287b56c583",
      "value": " 1654784/? [00:15&lt;00:00, 525555.99it/s]"
     }
    },
    "19acc9e6cb0146d89967f577562943e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feeef76f15c14b25b72461212963aa7d",
      "placeholder": "​",
      "style": "IPY_MODEL_c6d8da9fbad04865aa0c5fc537bf8e36",
      "value": " 0/28881 [00:00&lt;?, ?it/s]"
     }
    },
    "1efd6cdaeee040a48d1b16b8f3985b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04f5b74287bf4be0b4e0d044e60e7aa3",
       "IPY_MODEL_19acc9e6cb0146d89967f577562943e4"
      ],
      "layout": "IPY_MODEL_e2bb0f1f3db1490caa608c3f9abfc523"
     }
    },
    "227a416ebfb54db5bb7f1303c5519492": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23d5de05d2af40088f1de2c58427b707": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2740c04269d04b938ba71d0c5abec755": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ed78314be564c7082a0280f1fd4033f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f49e92ee7d64ddba0f95d03161ae4a2",
      "value": 1
     }
    },
    "276477d790254288b6cfd89375df4089": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4475099547014107860f85401acf7c0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fb0be940d8444198708855db05c3505": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68cae1c4adcd43f196900dad5555f7c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ed78314be564c7082a0280f1fd4033f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891e7615ddfe423984e003f35040f441": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aa68a2c68e84219a16b956ae7bdebe1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f49e92ee7d64ddba0f95d03161ae4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "afe68f44df754036bb85591d97732a46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d970d4a7eb4144a857b37baa070adc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68cae1c4adcd43f196900dad5555f7c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf8ee539368d450dbb60cccb42c99fb5",
      "value": 0
     }
    },
    "bbcbedb4b3d84eccb71277ea962371f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bf8ee539368d450dbb60cccb42c99fb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c6d8da9fbad04865aa0c5fc537bf8e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf3e3ef5e9b04210901c79b93089f99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd0797b88e694c0e878af40d24eb0de5",
      "placeholder": "​",
      "style": "IPY_MODEL_23d5de05d2af40088f1de2c58427b707",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "d3ef88cfb40a4640bc25df287b56c583": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d98b22b170e6481288a03facddedf448": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6d970d4a7eb4144a857b37baa070adc",
       "IPY_MODEL_cf3e3ef5e9b04210901c79b93089f99b"
      ],
      "layout": "IPY_MODEL_afe68f44df754036bb85591d97732a46"
     }
    },
    "dd0797b88e694c0e878af40d24eb0de5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2bb0f1f3db1490caa608c3f9abfc523": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3d36433bbf14ed39d3d42edffef1d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ee5fa6da69be4bfebac1cf3e8f4679c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8f9e19502d54dd595a8bbfe9aae728f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3d36433bbf14ed39d3d42edffef1d09",
      "value": 1
     }
    },
    "f8f9e19502d54dd595a8bbfe9aae728f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feeef76f15c14b25b72461212963aa7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
